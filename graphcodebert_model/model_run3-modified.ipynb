{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28665,"status":"ok","timestamp":1682998559874,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"Y-Xz9FW3Hk9v","outputId":"302fde89-c050-44dd-e5ce-9be393774939"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32636,"status":"ok","timestamp":1682998592506,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"dtSUyAA1Hk9z","outputId":"c8f280cf-c590-4b60-cbef-3d8c5bd69011"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tree_sitter\n","  Downloading tree_sitter-0.20.1.tar.gz (126 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: tree_sitter\n","  Building wheel for tree_sitter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tree_sitter: filename=tree_sitter-0.20.1-cp310-cp310-linux_x86_64.whl size=434939 sha256=aa9d7cb9c3d9e8135583b16a4066260bf75a0b525865e9eb9308b2c1f2ac5631\n","  Stored in directory: /root/.cache/pip/wheels/e6/d0/7a/a108b30f6615a71ca3a07ced1b149509d437a60c9d64820723\n","Successfully built tree_sitter\n","Installing collected packages: tree_sitter\n","Successfully installed tree_sitter-0.20.1\n"]}],"source":["!pip install transformers\n","!pip install tree_sitter"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1682998592507,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"IdrJV-_mHk90"},"outputs":[],"source":["import sys\n","sys.path.insert(0,'/content/drive/MyDrive/Colab_Notebooks/SyntaxSwap_model/ml_model/graphcodebert/model3-modified')\n","#sys.path.insert(0, '/content/drive/MyDrive/IIT/Final Year/Final Year Project/code/SyntaxSwap_model/ml_model/graphcodebert/model3')\n","# sys.path.insert(0, '/content/drive/Othercomputers/My Laptop/IIT/Final Year/Final Year Project/code/SyntaxSwap_model/ml_model/graphcodebert/model3')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":15745,"status":"ok","timestamp":1682998608246,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"cHstooSnHk90"},"outputs":[],"source":["# coding=utf-8\n","# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n","# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"\n","Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n","GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n","using a masked language modeling (MLM) loss.\n","\"\"\"\n","\n","from __future__ import absolute_import\n","import os\n","import sys\n","import pickle\n","import torch\n","import json\n","import random\n","# import logging\n","import argparse\n","import numpy as np\n","from io import open\n","from itertools import cycle\n","import torch.nn as nn\n","\n","#from model import Seq2Seq\n","# from original_model import Seq2Seq\n","from model2 import Seq2Seq\n","\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm, trange\n","from bleu import _bleu\n","from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n","from torch.utils.data.distributed import DistributedSampler\n","from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n","                          RobertaConfig, RobertaModel, RobertaTokenizer)\n","MODEL_CLASSES = {'roberta': (RobertaConfig, RobertaModel, RobertaTokenizer)}\n","\n","# logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","#                     datefmt = '%m/%d/%Y %H:%M:%S',\n","#                     level = logging.INFO)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":657,"status":"ok","timestamp":1682998608889,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"xyNgfonZHk91"},"outputs":[],"source":["from DFG import (\n","    DFG_java,\n","    DFG_javascript\n",")\n","from utils import (\n","    remove_comments_and_docstrings,\n","    tree_to_token_index,\n","    index_to_code_token, \n","    tree_to_variable_index\n",")\n","from tree_sitter import Language, Parser\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682998608890,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"BCwzfe5nHk92"},"outputs":[],"source":["dfg_function={\n","    'java':DFG_java,\n","    'javascript':DFG_javascript\n","}"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":479,"status":"ok","timestamp":1682998609366,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"VdNqCVscjN36"},"outputs":[],"source":["!cd drive/MyDrive/Colab_Notebooks/SyntaxSwap_model/ml_model/graphcodebert/model3/build_parser\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682998609367,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"AAlPrjiKkpj4"},"outputs":[],"source":["language_path = '/content/drive/MyDrive/Colab_Notebooks/SyntaxSwap_model/ml_model/graphcodebert/model3-modified/build_parser/my-languages.so'\n","#language_path = '/content/drive/MyDrive/IIT/Final Year/Final Year Project/code/SyntaxSwap_model/ml_model/graphcodebert/model3/build_parser/my-languages.so'"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1304,"status":"ok","timestamp":1682998610668,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"bdDe3eiGhdHH"},"outputs":[],"source":["\n","# # logger = logging.getLogger(__name__)\n","# !cp '/content/drive/MyDrive/Colab_Notebooks/SyntaxSwap_model/ml_model/graphcodebert/model3/build_parser/java_js.so'\n","# language_path = '/content/drive/MyDrive/Colab_Notebooks/SyntaxSwap_model/ml_model/graphcodebert/model3/build_parser/java_js.so'\n","\n","# import ctypes\n","# lang_lib = ctypes.CDLL(language_path)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1682998610668,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"7qSLZS6HHk92","outputId":"4a318402-6bfe-4dbe-d09d-32c1e32a0050"},"outputs":[{"output_type":"stream","name":"stdout","text":["lang java\n","lang javascript\n","Parsers : {'java': [<tree_sitter.Parser object at 0x7fba31bccdb0>, <function DFG_java at 0x7fbaf34e0dc0>], 'javascript': [<tree_sitter.Parser object at 0x7fba31bccd10>, <function DFG_javascript at 0x7fba31c0ed40>]}\n"]}],"source":["\n","#load parsers\n","parsers={}        \n","for lang in dfg_function:\n","    print(\"lang\",lang)\n","    LANGUAGE = Language(language_path, lang)\n","    parser = Parser()\n","    parser.set_language(LANGUAGE) \n","    parser = [parser,dfg_function[lang]]    \n","    parsers[lang]= parser\n","    \n","print(\"Parsers :\",parsers)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1682998610669,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"vISMkQ4zHk93"},"outputs":[],"source":["#remove comments, tokenize code and extract dataflow     \n","def extract_dataflow(code, parser,lang):\n","    #remove comments\n","    try:\n","        code=remove_comments_and_docstrings(code,lang)\n","    except:\n","        pass       \n","    try:\n","        tree = parser[0].parse(bytes(code,'utf8'))    \n","        root_node = tree.root_node  \n","        tokens_index=tree_to_token_index(root_node)     \n","        code=code.split('\\n')\n","        code_tokens=[index_to_code_token(x,code) for x in tokens_index]  \n","        index_to_code={}\n","        for idx,(index,code) in enumerate(zip(tokens_index,code_tokens)):\n","            index_to_code[index]=(idx,code)  \n","        try:\n","            DFG,_=parser[1](root_node,index_to_code,{}) \n","        except:\n","            DFG=[]\n","        DFG=sorted(DFG,key=lambda x:x[1])\n","        indexs=set()\n","        for d in DFG:\n","            if len(d[-1])!=0:\n","                indexs.add(d[1])\n","            for x in d[-1]:\n","                indexs.add(x)\n","        new_DFG=[]\n","        for d in DFG:\n","            if d[1] in indexs:\n","                new_DFG.append(d)\n","        dfg=new_DFG\n","    except:\n","        dfg=[]\n","    return code_tokens,dfg\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682998610669,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"3al1zL-aHk93"},"outputs":[],"source":["class Example(object):\n","    \"\"\"A single training/test example.\"\"\"\n","    def __init__(self,\n","                 source,\n","                 target,\n","                 lang\n","                 ):\n","        self.source = source\n","        self.target = target\n","        self.lang=lang\n","\n","\n","def read_examples(source_file='source.txt', target_file='target.txt'):\n","    \"\"\"Read examples from filename.\"\"\"\n","    examples=[]\n","    source = source_file\n","    target = target_file\n","        \n","    with open(source,encoding=\"utf-8\") as f1,open(target,encoding=\"utf-8\") as f2:\n","        for line1,line2 in zip(f1,f2):\n","            line1=line1.strip()\n","            line2=line2.strip()\n","            examples.append(\n","                Example(\n","                    source=line1,\n","                    target=line2,\n","                    lang=lang\n","                        ) \n","            )\n","\n","    return examples\n","\n","class InputFeatures(object):\n","    \"\"\"A single training/test features for a example.\"\"\"\n","    def __init__(self,\n","                 example_id,\n","                 source_ids,\n","                 position_idx,\n","                 dfg_to_code,\n","                 dfg_to_dfg,                 \n","                 target_ids,\n","                 source_mask,\n","                 target_mask,\n","\n","    ):\n","        self.example_id = example_id\n","        self.source_ids = source_ids\n","        self.position_idx = position_idx\n","        self.dfg_to_code = dfg_to_code\n","        self.dfg_to_dfg = dfg_to_dfg\n","        self.target_ids = target_ids\n","        self.source_mask = source_mask\n","        self.target_mask = target_mask  \n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682998610669,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"vatKD_S-Hk94"},"outputs":[],"source":["# parsers={}        \n","# for lang in dfg_function:\n","#     LANGUAGE = Language('build_parser/java_js.so', lang)\n","#     parser = Parser()\n","#     parser.set_language(LANGUAGE) \n","#     parser = [parser,dfg_function[lang]]    \n","#     parsers[lang]= parser"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682998610670,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"K_zt_-zhHk94"},"outputs":[],"source":["max_source_length = 320\n","max_target_length = 256\n","source_lang = \"java\"\n","target_lang = \"javascript\"\n","\n","def convert_examples_to_features(examples, tokenizer, stage=None):\n","    features = []\n","    for example_index, example in enumerate(tqdm(examples,total=len(examples))):\n","        ##extract data flow\n","        code_tokens,dfg=extract_dataflow(example.source,\n","                                         parsers[\"java\"],\n","                                         \"java\")\n","        code_tokens=[tokenizer.tokenize('@ '+x)[1:] if idx!=0 else tokenizer.tokenize(x) for idx,x in enumerate(code_tokens)]\n","        # ORIGINAL TO CURRENT TOKEN POSITION\n","        ori2cur_pos={}\n","        ori2cur_pos[-1]=(0,0)\n","        for i in range(len(code_tokens)):\n","            ori2cur_pos[i]=(ori2cur_pos[i-1][1],ori2cur_pos[i-1][1]+len(code_tokens[i]))    \n","        code_tokens=[y for x in code_tokens for y in x]  \n","        \n","        #truncating\n","        code_tokens=code_tokens[:max_source_length-3][:512-3]\n","        \n","        # Adds the special tokens [CLS] and [SEP] to the beginning and end of the token \n","        source_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n","        # convert the tokens to their corresponding token ids\n","        source_ids =  tokenizer.convert_tokens_to_ids(source_tokens)\n","\n","        position_idx = [i+tokenizer.pad_token_id + 1 for i in range(len(source_tokens))]\n","        dfg=dfg[:max_source_length-len(source_tokens)]\n","        \"\"\"\n","        Concatenates the dfg edge labels with the source_tokens list and adds a 0 to the\n","        position_idx list for each dfg edge label.\n","\n","        \"\"\"\n","        source_tokens+=[x[0] for x in dfg]\n","        \"\"\"\n","        Sets the token ids for the dfg edge labels to tokenizer.unk_token_id, indicating \n","        that they are unknown tokens.\n","        \"\"\"\n","        position_idx+=[0 for x in dfg]\n","        source_ids+=[tokenizer.unk_token_id for x in dfg]\n","        \"\"\"\n","        Pads the position_idx and source_ids lists with tokenizer.pad_token_id to ensure \n","        that they have the same length as max_source_length.\n","        \"\"\"\n","        padding_length=max_source_length-len(source_ids)\n","        position_idx+=[tokenizer.pad_token_id]*padding_length\n","        source_ids+=[tokenizer.pad_token_id]*padding_length  \n","\n","        \"\"\"\n","        Creates a source_mask list that indicates which tokens in the sequence are valid \n","        input tokens (1) and which ones are padding tokens (0)\n","        \"\"\"\n","        source_mask = [1] * (len(source_tokens))\n","        source_mask+=[0]*padding_length       \n","        \n","        #reindex\n","        reverse_index={}\n","        for idx,x in enumerate(dfg):\n","            reverse_index[x[1]]=idx\n","\n","        for idx,x in enumerate(dfg):\n","            dfg[idx]=x[:-1]+([reverse_index[i] for i in x[-1] if i in reverse_index],)    \n","        \n","        dfg_to_dfg=[x[-1] for x in dfg]\n","\n","        \"\"\"\n","        creates a list dfg_to_code where each element corresponds to a tuple containing \n","        the starting and ending positions of the code segment that corresponds to each node \n","        in the dataflow graph (dfg). The positions are expressed in terms of the original source code.\n","        \n","        \"\"\"\n","        dfg_to_code=[ori2cur_pos[x[1]] for x in dfg]\n","        length=len([tokenizer.cls_token]) # length of the special token [CLS], always 1\n","\n","        dfg_to_code=[(x[0]+length,x[1]+length) for x in dfg_to_code]   \n","\n","        #target\n","        if stage==\"test\":\n","            target_tokens = tokenizer.tokenize(\"None\")\n","        else:\n","            target_tokens = tokenizer.tokenize(example.target)[:max_target_length-2]\n","        \n","        target_tokens = [tokenizer.cls_token]+target_tokens+[tokenizer.sep_token]            \n","        target_ids = tokenizer.convert_tokens_to_ids(target_tokens)\n","        target_mask = [1] *len(target_ids)\n","        padding_length = max_target_length - len(target_ids)\n","        target_ids+=[tokenizer.pad_token_id]*padding_length\n","        target_mask+=[0]*padding_length   \n","   \n","        if example_index < 5:\n","            if stage=='train':\n","                print(\"*** Example ***\")\n","                print(\"source_tokens: {}\".format([x.replace('\\u0120','_') for x in source_tokens]))\n","                print(\"source_ids: {}\".format(' '.join(map(str, source_ids))))\n","                print(\"source_mask: {}\".format(' '.join(map(str, source_mask))))\n","                print(\"position_idx: {}\".format(position_idx))\n","                print(\"dfg_to_code: {}\".format(' '.join(map(str, dfg_to_code))))\n","                print(\"dfg_to_dfg: {}\".format(' '.join(map(str, dfg_to_dfg))))\n","                \n","                print(\"target_tokens: {}\".format([x.replace('\\u0120','_') for x in target_tokens]))\n","                print(\"target_ids: {}\".format(' '.join(map(str, target_ids))))\n","                print(\"target_mask: {}\".format(' '.join(map(str, target_mask))))\n","       \n","        features.append(\n","            InputFeatures(\n","                 example_index,\n","                 source_ids,\n","                 position_idx,\n","                 dfg_to_code,\n","                 dfg_to_dfg,\n","                 target_ids,\n","                 source_mask,\n","                 target_mask,\n","            )\n","        )\n","    return features"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682998610670,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"uAI_h5wBHk95"},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, examples, max_source_length):\n","        self.examples = examples\n","        self.max_source_length = max_source_length\n","        \n","    def __len__(self):\n","        return len(self.examples)\n","    \n","    def __getitem__(self, item):\n","        #calculate graph-guided masked function\n","        attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","        \n","        #calculate begin index of node and max length of input\n","        node_index=sum([i>1 for i in self.examples[item].position_idx])\n","        max_length=sum([i!=1 for i in self.examples[item].position_idx])\n","\n","        #sequence can attend to sequence\n","        attn_mask[:node_index,:node_index]=True\n","        #special tokens attend to all tokens\n","        for idx,i in enumerate(self.examples[item].source_ids):\n","            if i in [0,2]:\n","                attn_mask[idx,:max_length]=True\n","        #nodes attend to code tokens that are identified from\n","        for idx,(a,b) in enumerate(self.examples[item].dfg_to_code):\n","            if a<node_index and b<node_index:\n","                attn_mask[idx+node_index,a:b]=True\n","                attn_mask[a:b,idx+node_index]=True\n","        #nodes attend to adjacent nodes         \n","        for idx,nodes in enumerate(self.examples[item].dfg_to_dfg):\n","            for a in nodes:\n","                if a+node_index<len(self.examples[item].position_idx):\n","                    attn_mask[idx+node_index,a+node_index]=True  \n","                    \n","        return (torch.tensor(self.examples[item].source_ids),\n","                torch.tensor(self.examples[item].source_mask),\n","                torch.tensor(self.examples[item].position_idx),\n","                torch.tensor(attn_mask), \n","                torch.tensor(self.examples[item].target_ids),\n","                torch.tensor(self.examples[item].target_mask),)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682998610670,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"vAalSAhSHk95"},"outputs":[],"source":["def set_seed(seed=20):\n","    random.seed(seed)\n","    os.environ['PYHTONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"id":"nFD6D-JgST99"},"source":["### Data preperation"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682998610671,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"Rl6Ap-bDHk96"},"outputs":[],"source":["model_type = \"roberta\"\n","model_name_or_path = \"microsoft/graphcodebert-base\"\n","output_dir = \"/content/drive/MyDrive/Colab_Notebooks/output_dir\"\n","load_model_path = output_dir + \"/checkpoint-best-bleu/pytorch_model.bin\"\n","load_model_path = None\n","\n","# large dataset\n","\n","train_filename = \"\"\n","train_source_filename = \"/content/drive/MyDrive/Colab_Notebooks/snippets-programs-large-java-js/train-snippets_programs.java\"\n","train_target_filename = \"/content/drive/MyDrive/Colab_Notebooks/snippets-programs-large-java-js/train-snippets_programs.js\"\n","\n","dev_filename = \"\"\n","dev_source_filename = \"/content/drive/MyDrive/Colab_Notebooks/snippets-programs-large-java-js/val-snippets_programs.java\"\n","dev_target_filename = \"/content/drive/MyDrive/Colab_Notebooks/snippets-programs-large-java-js/val-snippets_programs.js\"\n","\n","test_filename = \"\"\n","test_source_filename = \"/content/drive/MyDrive/Colab_Notebooks/snippets-programs-large-java-js/test-snippets_programs.java\"\n","test_target_filename = \"/content/drive/MyDrive/Colab_Notebooks/snippets-programs-large-java-js/test-snippets_programs.js\"\n","\n","\n","# # small dataset\n","# train_source_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-javascript-snippets/train-Java-Javascript.java\"\n","# train_target_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-javascript-snippets/train-Java-Javascript.js\"\n","\n","# dev_source_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-javascript-snippets/val-Java-Javascript.java\"\n","# dev_target_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-javascript-snippets/val-Java-Javascript.js\"\n","\n","# test_source_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-javascript-snippets/test-Java-Javascript.java\"\n","# test_target_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-javascript-snippets/test-Java-Javascript.js\"\n","\n","# # extra small dataset\n","# train_source_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-js-extra-small/train-Java-Javascript.java\"\n","# train_target_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-js-extra-small/train-Java-Javascript.js\"\n","\n","# dev_source_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-js-extra-small/val-Java-Javascript.java\"\n","# dev_target_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-js-extra-small/val-Java-Javascript.js\"\n","\n","# test_source_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-js-extra-small/test-Java-Javascript.java\"\n","# test_target_filename = \"/content/drive/MyDrive/Colab_Notebooks/java-js-extra-small/test-Java-Javascript.js\"\n","\n","config_name = \"microsoft/graphcodebert-base\"\n","tokenizer_name = \"microsoft/graphcodebert-base\"\n","do_train = True\n","do_eval = True\n","do_test = True\n","do_lower_case = True\n","no_cuda = True\n","train_batch_size = 32\n","eval_batch_size = 12\n","gradient_accumulation_steps = 1\n","learning_rate = 5e-5\n","beam_size = 10\n","weight_decay = 0.0\n","adam_epsilon = 1e-8\n","max_grad_norm = 1.0\n","num_train_epochs = 3\n","max_steps = -1\n","eval_steps = 50\n","train_steps = -1\n","warmup_steps = 0\n","local_rank = -1\n","seed = 42\n","\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682998610672,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"d_2HnVFfHk97","outputId":"22887ef4-a3ea-4f6d-cf14-814842c120a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["# Setup CUDA, GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# device = torch.device(\"cpu\")\n","# try this out with mps\n","n_gpu = torch.cuda.device_count()\n","device = device\n","\n","# Set seed\n","# set_seed(seed)\n","print(device)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1682998610672,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"D5smxtTDHk97"},"outputs":[],"source":["# make dir if output_dir not exist\n","if os.path.exists(output_dir) is False:\n","    os.makedirs(output_dir)"]},{"cell_type":"markdown","source":["### Model build"],"metadata":{"id":"bIr0sLeKaP3U"}},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333,"referenced_widgets":["4bc870c0bbb14ea8acb74ba2e83f7671","17d14c7456ab4f55b6c19d6a54745711","069890ec49124f338a0763743d9364fa","13894002b6564362b50a985d24c2133b","da6234b794854404ae3405cd3db43abb","b91537d2e95645799e92ca3664767a08","2891390f37894ff6a70797fee4d3bbc7","481fab40fc1b4d128a8caef6489c7a00","32b1af328284431d952c1fdf472604d6","7a776ed44fff42c3aaa4511b118c2aca","21e8827b8eaa4a72a0cef1ea72736231","76c85f657655410788a1be2ac75132d0","499702c3cb7e466db645d151f7e73b7c","60ad2dae21e74057a54fd2b34ec7fe4f","25a54a192ffc410299c66acad4304b96","c6317caf45e7412e9eaa43fe1b7de75f","201c1b47eef14ca29862c0542905ef56","957331b112894fd4b446accdf5f9c583","e4752d3f4a294af7847850a06afb937e","05d49f42b6254d17bafc4341c981e619","4f24e98e8c82429f950fd89f7b3d2dd4","e1d20d159700486595df24f9ff53d626","e4b22debe56c4cc2aca69df0444e8fca","3b1e7eaa81c74942b53a8c7d2c0204cc","5b17e632829941f5b08d28de0f703d36","c8bc889d42ae49869f98753f459284dc","839f476ebab448e3b15219498d0f33fa","3a7cf6d192444ed0a2e8955a07887d73","d6f84f35701a423abae3e3c969038b8f","655f0cf6ff6b41ce9c818567433f260b","c7905b1add1344a096598a01eccf49df","3e385fc61f2b4065810276f5b383b0ab","bd981e62245441b7b5c9edd60e8c6129","2b9ee8508b7a4c3a914251c51143b585","fe2aa746b7d1432d81e5810f3bdf7881","d123bfd2d4de4be5a151485ff5deaaea","924304d88c644dde8c7bed06237d953c","9b3dfa982a714584b64a3c1c1c315317","c0c887af49d94d48ba50668a6dc7b373","89b01fdd6dda414ba51bb4b62ebf31fa","e88a15b7f9534c219bfe3c4bd1790d38","21456c6e6da94a258759c75d8bea8888","d1260d6a650140949ae165e7d089620b","945ebbb23048435899bd2a2335e1a50f","ce92f0980ff443e9bada0b86be2ff049","6064152bf5e847b498c1e0fe272b01aa","1fbfc6dc7387458ea876c2bbcc306036","e442d920b54346159e55704fb1e8c172","a28152783b794894b7f77bbb31a34cdb","1a76a77b8e4d44e2b38618fb347adafc","6757578e888443ad8d63159c0f288be6","511e37c3542e4db59430cb28ba656ca7","9d01f7cc1c1b434e98760389bf1cbb84","59ec2689567242fd9ec693932bd6bdc3","a51d7707903e4b2daac79e582b41fbf3","77e7253393d5438da4e73945237bfdb0","1d42f12b146b467c9c962419fe710fc7","44e4c1f859f24ae6b7fc850eb0ff39dc","07c0356c4f324fcf9ed01bc0ab476cb7","0876e399f9144ed5b55f91092e4fdea1","ca28db165bd64db7aaedb22456dfa0c1","4f5c4aadaa474c22bd6f7240a5e78800","6041f5aa66f647d595017343ec79aea7","f6f8c8ffa39d4a609f0d506d6786b8e7","d0fba310081040a8bf01d7828a40a03f","b8fe38c75e9c4ffc8dd2c035cb857333"]},"executionInfo":{"elapsed":9384,"status":"ok","timestamp":1682998620047,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"V0hiYzT0Hk98","outputId":"aa87a6a2-b180-4134-87fd-4290a7dfc348"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/539 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bc870c0bbb14ea8acb74ba2e83f7671"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76c85f657655410788a1be2ac75132d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4b22debe56c4cc2aca69df0444e8fca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b9ee8508b7a4c3a914251c51143b585"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce92f0980ff443e9bada0b86be2ff049"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77e7253393d5438da4e73945237bfdb0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["\n"," creating the pos table inside the relative positional encoding attention mechanism \n","\n"]}],"source":["config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n","config = config_class.from_pretrained(config_name)\n","tokenizer = tokenizer_class.from_pretrained(tokenizer_name )\n","\n","#build model\n","# Loads the pretrained weights for the model\n","encoder = model_class.from_pretrained(model_name_or_path,config=config)\n","\n","\"\"\"\n","Why we need the specify d_model and nhead?\n","\n","In the transformer-based decoder model, the input and output embeddings for each layer are transformed \n","using self-attention and multi-head attention mechanisms. The d_model parameter specifies the size of \n","these input and output embeddings. Since the input embeddings for the decoder come from the output of \n","the encoder, it is necessary to make sure that the d_model parameter matches the hidden size of the \n","encoder, which is specified in the config object.\n","\n","The nhead parameter specifies the number of attention heads to use in the multi-head attention mechanism. \n","More attention heads allow the model to attend to more fine-grained details of the input sequence, but \n","also increase the computational cost of the model. The optimal number of attention heads depends on the \n","specific task and dataset, and is typically chosen through hyperparameter tuning.\n","\"\"\"\n","decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n","decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n","\n","\"\"\"\n","The above encoder, decoder layer and decoder code initializes an encoder-decoder model for code-to-code \n","translation using a pre-trained language model as the encoder and a transformer-based decoder with multiple \n","layers and attention heads. The code leverages the strengths of the pre-trained language model to encode the \n","input code, and the transformer-based decoder to generate the translated code.\n","\"\"\"\n","\n","model=Seq2Seq(encoder=encoder,decoder=decoder,config=config,\n","                beam_size=beam_size,max_length=max_target_length,\n","                sos_id=tokenizer.cls_token_id,eos_id=tokenizer.sep_token_id)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1682998620047,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"xV1IqCaNcEsJ","outputId":"d5ccd1be-418c-46d5-92f0-a8952749857e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of model parameters: 172503552 (Number of trainable parameters: 172503552)\n"]}],"source":["###### Count and print number of parameters ######\n","total_parameters = sum(param.numel() for param in model.parameters())\n","total_trainable_parameters = sum(param.numel() for param in model.parameters() if param.requires_grad)\n","print(\"Number of model parameters: {} (Number of trainable parameters: {})\".format(total_parameters, total_trainable_parameters))"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":9797,"status":"ok","timestamp":1682998629824,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"IjWQ02J-Hk98"},"outputs":[],"source":["if load_model_path is not None:\n","    print(\"reload model from {}\".format(load_model_path))\n","    model.load_state_dict(torch.load(load_model_path))\n","    \n","model.to(device)\n","if n_gpu > 1:\n","    # multi-gpu training\n","    model = torch.nn.DataParallel(model)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1682998629825,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"jqHZcNsjApnu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1682998629826,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"khC3Rab8cEsJ"},"outputs":[],"source":["# Below lists are to store the values to plot the graph | self composed\n","\n","train_losses = []\n","eval_ppls = []\n","eval_bleus = []\n","epochs = []\n"]},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"Bm2ORF99aUUz"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7631724,"status":"ok","timestamp":1681504518359,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"5yFBdGgXHk98","outputId":"7857f612-468f-4143-d04b-8b774b1e4247"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 62/77811 [00:00<06:50, 189.50it/s]"]},{"name":"stdout","output_type":"stream","text":["*** Example ***\n","source_tokens: ['<s>', 'import', '_java', '_.', '_util', '_.', '_*', '_;', '_class', '_G', 'FG', '_{', '_static', '_int', '_max', 'Pres', 'um', '_(', '_int', '_[', '_]', '_a', '_,', '_int', '_[', '_]', '_b', '_)', '_{', '_', '_', '</s>']\n","source_ids: 0 41975 46900 479 14258 479 1009 25606 1380 272 25077 25522 25156 6979 19220 28917 783 36 6979 646 27779 10 2156 6979 646 27779 741 4839 25522 1437 1437 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","position_idx: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","dfg_to_code: \n","dfg_to_dfg: \n","target_tokens: ['<s>', 'function', '_max', 'Pres', 'um', '_(', '_a', '_,', '_b', '_)', '_{', '</s>']\n","target_ids: 0 35435 19220 28917 783 36 10 2156 741 4839 25522 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","*** Example ***\n","source_tokens: ['<s>', 'int', '_X', '_=', '_Math', '_.', '_max', '_(', '_a', '_[', '_0', '_]', '_,', '_0', '_)', '_;', '</s>', 'X', 'X', 'X', 'X', 'X', 'Math', 'max', 'a', '0', '0']\n","source_ids: 0 2544 1577 5457 11945 479 19220 36 10 646 321 27779 2156 321 4839 25606 2 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","position_idx: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","dfg_to_code: (2, 3) (2, 3) (2, 3) (2, 3) (2, 3) (4, 5) (6, 7) (8, 9) (10, 11) (13, 14)\n","dfg_to_dfg: [5] [6] [7] [8] [9] [] [] [] [] []\n","target_tokens: ['<s>', 'let', '_X', '_=', '_Math', '_.', '_max', '_(', '_a', '_[', '_0', '_]', '_,', '_0', '_)', '_;', '</s>']\n","target_ids: 0 2716 1577 5457 11945 479 19220 36 10 646 321 27779 2156 321 4839 25606 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","*** Example ***\n","source_tokens: ['<s>', 'for', '_(', '_int', '_i', '_=', '_1', '_;', '_i', '_<', '_a', '_.', '_length', '_;', '_i', '_++', '_)', '_{', '_a', '_[', '_i', '_]', '_+=', '_a', '_[', '_i', '_-', '_1', '_]', '_;', '_X', '_=', '_Math', '_.', '_max', '_(', '_X', '_,', '_a', '_[', '_i', '_]', '_)', '_;', '_}', '</s>', 'i', '1', 'i', 'a', 'length', 'i', 'a', 'i', 'a', 'i', '1', 'X', 'Math', 'max', 'X', 'a', 'i']\n","source_ids: 0 1990 36 6979 939 5457 112 25606 939 28696 10 479 5933 25606 939 48793 4839 25522 10 646 939 27779 49371 10 646 939 111 112 27779 25606 1577 5457 11945 479 19220 36 1577 2156 10 646 939 27779 4839 25606 35524 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","position_idx: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","dfg_to_code: (4, 5) (6, 7) (8, 9) (10, 11) (12, 13) (14, 15) (18, 19) (20, 21) (23, 24) (25, 26) (27, 28) (30, 31) (32, 33) (34, 35) (36, 37) (38, 39) (40, 41)\n","dfg_to_dfg: [1] [] [0, 7] [6] [4] [5] [8, 9, 10] [8, 9, 10] [3, 6] [5] [] [12, 13, 14, 15, 16] [12] [13] [11] [6] [7]\n","target_tokens: ['<s>', 'for', '_(', '_let', '_i', '_=', '_1', '_;', '_i', '_<', '_a', '_.', '_length', '_;', '_i', '_++', '_)', '_{', '_a', '_[', '_i', '_]', '_+=', '_a', '_[', '_i', '_-', '_1', '_]', '_;', '_X', '_=', '_Math', '_.', '_max', '_(', '_X', '_,', '_a', '_[', '_i', '_]', '_)', '_;', '_}', '</s>']\n","target_ids: 0 1990 36 905 939 5457 112 25606 939 28696 10 479 5933 25606 939 48793 4839 25522 10 646 939 27779 49371 10 646 939 111 112 27779 25606 1577 5457 11945 479 19220 36 1577 2156 10 646 939 27779 4839 25606 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","*** Example ***\n","source_tokens: ['<s>', 'int', '_Y', '_=', '_Math', '_.', '_max', '_(', '_b', '_[', '_0', '_]', '_,', '_0', '_)', '_;', '</s>', 'Y', 'Y', 'Y', 'Y', 'Y', 'Math', 'max', 'b', '0', '0']\n","source_ids: 0 2544 854 5457 11945 479 19220 36 741 646 321 27779 2156 321 4839 25606 2 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","position_idx: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","dfg_to_code: (2, 3) (2, 3) (2, 3) (2, 3) (2, 3) (4, 5) (6, 7) (8, 9) (10, 11) (13, 14)\n","dfg_to_dfg: [5] [6] [7] [8] [9] [] [] [] [] []\n","target_tokens: ['<s>', 'let', '_Y', '_=', '_Math', '_.', '_max', '_(', '_b', '_[', '_0', '_]', '_,', '_0', '_)', '_;', '</s>']\n","target_ids: 0 2716 854 5457 11945 479 19220 36 741 646 321 27779 2156 321 4839 25606 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","*** Example ***\n","source_tokens: ['<s>', 'for', '_(', '_int', '_i', '_=', '_1', '_;', '_i', '_<', '_b', '_.', '_length', '_;', '_i', '_++', '_)', '_{', '_b', '_[', '_i', '_]', '_+=', '_b', '_[', '_i', '_-', '_1', '_]', '_;', '_Y', '_=', '_Math', '_.', '_max', '_(', '_Y', '_,', '_b', '_[', '_i', '_]', '_)', '_;', '_}', '_return', '_X', '_+', '_Y', '_;', '_}', '</s>', 'i', '1', 'i', 'b', 'length', 'i', 'b', 'i', 'b', 'i', '1', 'Y', 'Math', 'max', 'Y', 'b', 'i', 'Y']\n","source_ids: 0 1990 36 6979 939 5457 112 25606 939 28696 741 479 5933 25606 939 48793 4839 25522 741 646 939 27779 49371 741 646 939 111 112 27779 25606 854 5457 11945 479 19220 36 854 2156 741 646 939 27779 4839 25606 35524 671 1577 2055 854 25606 35524 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","position_idx: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","dfg_to_code: (4, 5) (6, 7) (8, 9) (10, 11) (12, 13) (14, 15) (18, 19) (20, 21) (23, 24) (25, 26) (27, 28) (30, 31) (32, 33) (34, 35) (36, 37) (38, 39) (40, 41) (48, 49)\n","dfg_to_dfg: [1] [] [0, 7] [6] [4] [5] [8, 9, 10] [8, 9, 10] [3, 6] [5] [] [12, 13, 14, 15, 16] [12] [13] [11] [6] [7] [11]\n","target_tokens: ['<s>', 'for', '_(', '_let', '_i', '_=', '_1', '_;', '_i', '_<', '_b', '_.', '_length', '_;', '_i', '_++', '_)', '_{', '_b', '_[', '_i', '_]', '_+=', '_b', '_[', '_i', '_-', '_1', '_]', '_;', '_Y', '_=', '_Math', '_.', '_max', '_(', '_Y', '_,', '_b', '_[', '_i', '_]', '_)', '_;', '_}', '_return', '_X', '_+', '_Y', '_;', '_}', '</s>']\n","target_ids: 0 1990 36 905 939 5457 112 25606 939 28696 741 479 5933 25606 939 48793 4839 25522 741 646 939 27779 49371 741 646 939 111 112 27779 25606 854 5457 11945 479 19220 36 854 2156 741 646 939 27779 4839 25606 35524 671 1577 2055 854 25606 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 77811/77811 [03:46<00:00, 343.42it/s]\n","/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["***** Running training *****\n","  Num examples = %d 77811\n","  Batch size = %d 32\n","  Num epoch = %d 3\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/2432 [00:00<?, ?it/s]<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","epoch 0 loss 1.919: 100%|██████████| 2432/2432 [30:11<00:00,  1.34it/s]\n","100%|██████████| 4301/4301 [00:12<00:00, 344.28it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","***** Running evaluation *****\n","  Num examples = %d 4301\n","  Batch size = %d 12\n"]},{"name":"stderr","output_type":"stream","text":["\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n"]},{"name":"stdout","output_type":"stream","text":["  %s = %s eval_ppl 1.57989\n","  %s = %s global_step 2433\n","  %s = %s train_loss 1.919\n","  ********************\n","  Best ppl:%s 1.57989\n","  ********************\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:02<00:00, 357.04it/s]\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n"]},{"name":"stdout","output_type":"stream","text":["----- presenting bleu -----\n","  bleu-4 = 67.33 \n","  xMatch = 36.1 \n","  ********************\n","  Best BLEU+xMatch:%s 103.43\n","  ********************\n","\n","went through one full loop epoch: 0\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/2432 [00:00<?, ?it/s]<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","epoch 1 loss 0.32: 100%|██████████| 2432/2432 [30:08<00:00,  1.34it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","***** Running evaluation *****\n","  Num examples = %d 4301\n","  Batch size = %d 12\n"]},{"name":"stderr","output_type":"stream","text":["\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n"]},{"name":"stdout","output_type":"stream","text":["  %s = %s eval_ppl 1.2966\n","  %s = %s global_step 4865\n","  %s = %s train_loss 0.32\n","  ********************\n","  Best ppl:%s 1.2966\n","  ********************\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n"]},{"name":"stdout","output_type":"stream","text":["----- presenting bleu -----\n","  bleu-4 = 75.1 \n","  xMatch = 49.1 \n","  ********************\n","  Best BLEU+xMatch:%s 124.19999999999999\n","  ********************\n","\n","went through one full loop epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/2432 [00:00<?, ?it/s]<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","epoch 2 loss 0.2043: 100%|██████████| 2432/2432 [30:08<00:00,  1.34it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","***** Running evaluation *****\n","  Num examples = %d 4301\n","  Batch size = %d 12\n"]},{"name":"stderr","output_type":"stream","text":["\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n"]},{"name":"stdout","output_type":"stream","text":["  %s = %s eval_ppl 1.2517\n","  %s = %s global_step 7297\n","  %s = %s train_loss 0.2043\n","  ********************\n","  Best ppl:%s 1.2517\n","  ********************\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n"]},{"name":"stdout","output_type":"stream","text":["----- presenting bleu -----\n","  bleu-4 = 76.38 \n","  xMatch = 51.9 \n","  ********************\n","  Best BLEU+xMatch:%s 128.28\n","  ********************\n","\n","went through one full loop epoch: 2\n"]}],"source":["if do_train:\n","    # Prepare training data loader\n","    train_examples = read_examples(train_source_filename, train_target_filename)\n","    train_features = convert_examples_to_features(train_examples, tokenizer,stage='train')\n","    train_data = TextDataset(train_features, max_source_length)\n","    train_sampler = RandomSampler(train_data)\n","    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size//gradient_accumulation_steps,num_workers=4)\n","\n","    num_train_optimization_steps =  train_steps\n","\n","    # Prepare optimizer and schedule (linear warmup and decay)\n","    no_decay = ['bias', 'LayerNorm.weight']\n","    \"\"\"\n","    Groups the model parameters into two sets,\n","    one with weight decay applied and the other without weight decay\n","    \"\"\"\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=len(train_dataloader)*num_train_epochs*0.1,num_training_steps=len(train_dataloader)*num_train_epochs)\n","\n","    #Start training\n","    print(\"***** Running training *****\")\n","    print(\"  Num examples = %d\", len(train_examples))\n","    print(\"  Batch size = %d\", train_batch_size)\n","    print(\"  Num epoch = %d\", num_train_epochs)\n","    \n","    model.train()\n","    dev_dataset={}\n","    nb_tr_examples, nb_tr_steps,tr_loss,global_step,best_bleu,best_loss = 0, 0,0,0,0,1e6 \n","    for epoch in range(num_train_epochs):\n","        bar = tqdm(train_dataloader,total=len(train_dataloader))\n","        for batch in bar:\n","            # print(\"batch :\", batch)\n","            batch = tuple(t.to(device) for t in batch)\n","            source_ids,source_mask,position_idx,att_mask,target_ids,target_mask = batch\n","            loss,_,_ = model(source_ids,source_mask,position_idx,att_mask,target_ids,target_mask)\n","\n","            if n_gpu > 1:\n","                loss = loss.mean() # mean() to average on multi-gpu.\n","            if gradient_accumulation_steps > 1:\n","                loss = loss / gradient_accumulation_steps\n","                \n","            tr_loss += loss.item()\n","            train_loss=round(tr_loss*gradient_accumulation_steps/(nb_tr_steps+1),4)\n","            bar.set_description(\"epoch {} loss {}\".format(epoch,train_loss))\n","            nb_tr_examples += source_ids.size(0)\n","            nb_tr_steps += 1\n","            loss.backward()\n","\n","            if (nb_tr_steps + 1) % gradient_accumulation_steps == 0:\n","                #Update parameters\n","                optimizer.step()\n","                optimizer.zero_grad()\n","                scheduler.step()\n","                global_step += 1\n","\n","        if do_eval and epoch in [ int(num_train_epochs*(i+1)//20) for i in range(20)]:\n","            #Eval model with dev dataset\n","            tr_loss = 0\n","            nb_tr_examples, nb_tr_steps = 0, 0                     \n","            eval_flag=False    \n","            if 'dev_loss' in dev_dataset:\n","                eval_examples,eval_data=dev_dataset['dev_loss']\n","            else:\n","                eval_examples = read_examples(dev_source_filename, dev_target_filename)\n","                eval_features = convert_examples_to_features(eval_examples, tokenizer,stage='dev')\n","                eval_data = TextDataset(eval_features, max_source_length)\n","                dev_dataset['dev_loss']=eval_examples,eval_data\n","            eval_sampler = SequentialSampler(eval_data)\n","            eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size,num_workers=4)\n","\n","            print(\"\\n***** Running evaluation *****\")\n","            print(\"  Num examples = %d\", len(eval_examples))\n","            print(\"  Batch size = %d\", eval_batch_size)\n","\n","            #Start Evaling model\n","            model.eval()\n","            eval_loss,tokens_num = 0,0\n","            for batch in eval_dataloader:\n","                batch = tuple(t.to(device) for t in batch)               \n","                source_ids,source_mask,position_idx,att_mask,target_ids,target_mask = batch\n","                with torch.no_grad():\n","                    _,loss,num = model(source_ids,source_mask,position_idx,att_mask,target_ids,target_mask)     \n","                eval_loss += loss.sum().item()\n","                tokens_num += num.sum().item()\n","            #Pring loss of dev dataset    \n","            model.train()\n","            eval_loss = eval_loss / tokens_num\n","            result = {'eval_ppl': round(np.exp(eval_loss),5),\n","                        'global_step': global_step+1,\n","                        'train_loss': round(train_loss,5)}\n","            for key in sorted(result.keys()):\n","                print(\"  %s = %s\", key, str(result[key]))\n","            print(\"  \"+\"*\"*20)   \n","\n","            #save last checkpoint\n","            last_output_dir = os.path.join(output_dir, 'checkpoint-last')\n","            if not os.path.exists(last_output_dir):\n","                os.makedirs(last_output_dir)\n","            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n","            output_model_file = os.path.join(last_output_dir, \"pytorch_model.bin\")\n","            torch.save(model_to_save.state_dict(), output_model_file)                    \n","            if eval_loss<best_loss:\n","                \"\"\"\n","                Best ppl refers to the best (lowest) perplexity encountered during the evaluation\n","                of the model. Perplexity (ppl) is a common metric used to evaluate the performance\n","                of language models. \n","                \"\"\"\n","                print(\"  Best ppl:%s\",round(np.exp(eval_loss),5))\n","                print(\"  \"+\"*\"*20)\n","                best_loss=eval_loss\n","                # Save best checkpoint for best ppl\n","                output_dir = os.path.join(output_dir, 'checkpoint-best-ppl')\n","                if not os.path.exists(output_dir):\n","                    os.makedirs(output_dir)\n","                model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n","                output_model_file = os.path.join(output_dir, \"pytorch_model.bin\")\n","                torch.save(model_to_save.state_dict(), output_model_file)  \n","\n","\n","            #Calculate bleu  \n","            if 'dev_bleu' in dev_dataset:\n","                eval_examples,eval_data=dev_dataset['dev_bleu']\n","            else:\n","                eval_examples = read_examples(dev_source_filename, dev_target_filename)\n","                eval_examples = random.sample(eval_examples,min(1000,len(eval_examples)))\n","                eval_features = convert_examples_to_features(eval_examples, tokenizer,stage='test')\n","                eval_data = TextDataset(eval_features, max_source_length)\n","                dev_dataset['dev_bleu']=eval_examples,eval_data\n","\n","            eval_sampler = SequentialSampler(eval_data)\n","            eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size,num_workers=4)\n","            model.eval() \n","            p=[]\n","            for batch in eval_dataloader:\n","                batch = tuple(t.to(device) for t in batch)\n","                source_ids,source_mask,position_idx,att_mask,target_ids,target_mask = batch                 \n","                with torch.no_grad():\n","                    preds = model(source_ids,source_mask,position_idx,att_mask)  \n","                    for pred in preds:\n","                        t=pred[0].cpu().numpy()\n","                        t=list(t)\n","                        if 0 in t:\n","                            t=t[:t.index(0)]\n","                        text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n","                        p.append(text)\n","            model.train()\n","            predictions=[]\n","            accs=[]\n","            with open(os.path.join(output_dir,\"dev.output\"),'w') as f, open(os.path.join(output_dir,\"dev.gold\"),'w') as f1:\n","                for ref,gold in zip(p,eval_examples):\n","                    predictions.append(ref)\n","                    f.write(ref+'\\n')\n","                    f1.write(gold.target+'\\n')     \n","                    accs.append(ref==gold.target)\n","\n","            dev_bleu=round(_bleu(os.path.join(output_dir, \"dev.gold\"), os.path.join(output_dir, \"dev.output\")),2)\n","            xmatch=round(np.mean(accs)*100,4)\n","            print(\"----- presenting bleu -----\")\n","            print(\"  %s = %s \"%(\"bleu-4\",str(dev_bleu)))\n","            print(\"  %s = %s \"%(\"xMatch\",str(round(np.mean(accs)*100,4))))\n","            print(\"  \"+\"*\"*20)    \n","            if dev_bleu+xmatch>best_bleu:\n","                print(\"  Best BLEU+xMatch:%s\",dev_bleu+xmatch)\n","                print(\"  \"+\"*\"*20)\n","                best_bleu=dev_bleu+xmatch\n","                # Save best checkpoint for best bleu\n","                output_dir = os.path.join(output_dir, 'checkpoint-best-bleu')\n","                if not os.path.exists(output_dir):\n","                    os.makedirs(output_dir)\n","                model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n","                output_model_file = os.path.join(output_dir, \"pytorch_model.bin\")\n","                torch.save(model_to_save.state_dict(), output_model_file)\n","\n","            # self composed\n","            train_losses.append(train_loss) #SC\n","            eval_ppls.append(result['eval_ppl']) #SC\n","            epochs.append(epoch) #SC\n","\n","            eval_bleus.append(dev_bleu) #SC\n","\n","\n","        print(\"\\nwent through one full loop epoch:\", epoch)   \n","\n","torch.save(model, \"/content/drive/MyDrive/syntax_swap_modelv2.pt\")\n","torch.save(model.state_dict(), \"/content/drive/MyDrive/syntax_swap_model_dictv2.pt\")\n","torch.save(tokenizer, \"/content/drive/MyDrive/syntax_swap_tokenizerv2.pt\")\n","\n","\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":1519,"status":"ok","timestamp":1682959140457,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"ydxpeovvDIZN","outputId":"e1739a5d-09be-4bb6-a07b-449a91ef7125"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 3 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Plotting logic | self composed\n","\n","plt.figure(figsize=(12, 6))\n","\n","plt.subplot(1, 3, 1)\n","plt.plot(epochs, train_losses)\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Loss')\n","plt.title('Training Loss over Time')\n","\n","plt.subplot(1, 3, 2)\n","plt.plot(epochs, eval_ppls)\n","plt.xlabel('Epoch')\n","plt.ylabel('Evaluation Perplexity')\n","plt.title('Evaluation Perplexity over Time')\n","\n","plt.subplot(1, 3, 3)\n","plt.plot(epochs, eval_bleus)\n","plt.xlabel('Epoch')\n","plt.ylabel('Evaluation BLEU Score')\n","plt.title('Evaluation BLEU Score over Time')\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":375,"status":"ok","timestamp":1682959144602,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"ORm-zn3zJ1jQ","outputId":"e6809ba0-a5ac-4411-f399-e3a46af32046"},"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}],"source":["print(train_losses)"]},{"cell_type":"markdown","metadata":{"id":"M_-rs3BtaMwP"},"source":["### Testing the translations"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":10026,"status":"ok","timestamp":1682998650373,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"M96e2ibwY83J"},"outputs":[],"source":["model = torch.load('/content/drive/MyDrive/syntax_swap_modelv2.pt', map_location=torch.device('cuda'))\n","tokenizer = torch.load('/content/drive/MyDrive/syntax_swap_tokenizerv2.pt', map_location = torch.device('cuda'))"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":4996,"status":"ok","timestamp":1682998655353,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"wadP2trqcY5r","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f325de81-f5ba-414f-c6cc-088796b7cd41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyter3\n","  Downloading pyter3-0.3-py3-none-any.whl (4.1 kB)\n","Installing collected packages: pyter3\n","Successfully installed pyter3-0.3\n"]}],"source":["!pip install pyter3"]},{"cell_type":"code","source":["import pyter"],"metadata":{"id":"EyWdm-IjKFoq","executionInfo":{"status":"ok","timestamp":1682998655354,"user_tz":-330,"elapsed":20,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVfPc-I0762A","outputId":"ab1de6a2-395b-4b05-eb0c-30c6057764bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test file: /content/drive/MyDrive/Colab_Notebooks/snippets-programs-large-java-js/test-snippets_programs.java & /content/drive/MyDrive/Colab_Notebooks/snippets-programs-large-java-js/test-snippets_programs.js\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 7886/7886 [00:40<00:00, 196.56it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","  0%|          | 0/658 [00:00<?, ?it/s]<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","100%|██████████| 658/658 [3:22:22<00:00, 18.45s/it]\n"]},{"output_type":"stream","name":"stdout","text":["  bleu-4 = 79.06 \n","  xMatch = 56.1755 \n","  ********************\n"]}],"source":["if do_test:\n","    print(\"Test file: {} & {}\".format(test_source_filename, test_target_filename))\n","    eval_examples = read_examples(test_source_filename, test_target_filename)\n","    eval_features = convert_examples_to_features(eval_examples, tokenizer,stage='test')\n","    eval_data = TextDataset(eval_features, max_source_length) \n","\n","    # Calculate bleu\n","    eval_sampler = SequentialSampler(eval_data)\n","    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size,num_workers=4)\n","\n","    model.eval() \n","    p=[]\n","    for batch in tqdm(eval_dataloader,total=len(eval_dataloader)):\n","        batch = tuple(t.to(device) for t in batch)\n","        source_ids,source_mask,position_idx,att_mask,target_ids,target_mask = batch                    \n","        with torch.no_grad():\n","            preds = model(source_ids,source_mask,position_idx,att_mask)  \n","            for pred in preds:\n","                t=pred[0].cpu().numpy()\n","                t=list(t)\n","                if 0 in t:\n","                    t=t[:t.index(0)]\n","                text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n","                p.append(text)\n","    model.train()\n","    predictions=[]\n","    accs=[]\n","    with open(os.path.join(output_dir,\"test_predicted.output\"),'w') as f, open(os.path.join(output_dir,\"test_true.gold\"),'w') as f1:\n","        for ref,gold in zip(p,eval_examples):\n","            predictions.append(ref)\n","            f.write(ref+'\\n')\n","            f1.write(gold.target+'\\n')    \n","            accs.append(ref==gold.target)\n","    dev_bleu=round(_bleu(os.path.join(output_dir, \"test_true.gold\"), \n","                            os.path.join(output_dir, \"test_predicted.output\")),2)\n","    print(\"  %s = %s \"%(\"bleu-4\",str(dev_bleu)))\n","    print(\"  %s = %s \"%(\"xMatch\",str(round(np.mean(accs)*100,4))))\n","    print(\"  \"+\"*\"*20)  \n","\n","   "]},{"cell_type":"code","source":[" # Translation edit rate (self-composed) | Moved to here becuase it takes some time\n","ter_scores = []\n","for pred, gold in zip(predictions, eval_examples):\n","  pred_tokens = pred.split()\n","  gold_tokens = gold.target.split()\n","  ter = pyter.ter(pred_tokens, gold_tokens)\n","  ter_scores.append(ter)\n","\n","avg_ter = np.mean(ter_scores)\n","ter_percent = avg_ter * 100\n","print(\"  %s = %.2f%% \" % (\"TER\", round(ter_percent, 2)))"],"metadata":{"id":"Ud8dFiI9f-ma"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sD2R8kBIHk99"},"outputs":[],"source":["torch.save(model, \"/content/drive/MyDrive/gcodebert_java-js_smallmodel1.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QH8yb2Lxd65U"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYLVhcQVCTkF"},"outputs":[],"source":["trainned_model = '/content/drive/MyDrive/IIT/Final Year/Final Year Project/code/SyntaxSwap_model/ml_model/graphcodebert/model3/complete_modelv4.pt'\n","trainned_model2 = '/content/drive/MyDrive/gcodebert_java-js_model2.pt'\n","trainned_model3 = '/content/drive/MyDrive/gcodebert_java-js_model3.pt'\n","trainned_model4 = '/content/drive/MyDrive/complete_modelv5.pt'\n","\n","import torch\n","from transformers import RobertaTokenizer\n","# model = torch.load(trainned_model4, map_location=torch.device('cuda'))\n","# tokenizer = RobertaTokenizer.from_pretrained('microsoft/graphcodebert-base')\n","\n","model = torch.load('/content/drive/MyDrive/syntax_swap_modelv2.pt', map_location=torch.device('cuda'))\n","tokenizer = torch.load('/content/drive/MyDrive/syntax_swap_tokenizerv2.pt', map_location = torch.device('cuda'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9C5-5UYFHaj"},"outputs":[],"source":["model.eval()\n","\n","# import javalang\n","java_code = \"\"\"\n","ArrayList < Integer > al = new ArrayList < > ( ) ;\n","if (al.length > 4) {\n","  System.out.println(\"greater than 4\")\n","}\n","\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvFLsGIQFHak"},"outputs":[],"source":["class Example(object):\n","    \"\"\"A single training/test example.\"\"\"\n","    def __init__(self,source, lang):\n","        self.source = source\n","        self.lang = lang"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pXFBF0EFHak"},"outputs":[],"source":["example = Example(source=java_code.strip(), lang='java')\n","examples = []\n","examples.append(example)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1681509257287,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"zTGlDJYFFHak","outputId":"142bb76b-edd8-477f-8ca6-eabd339a5119"},"outputs":[{"name":"stdout","output_type":"stream","text":["Parsers : {'java': [<tree_sitter.Parser object at 0x7f656bdd77d0>, <function DFG_java at 0x7f664a15dee0>], 'javascript': [<tree_sitter.Parser object at 0x7f656bdd7750>, <function DFG_javascript at 0x7f656bd98790>]}\n"]}],"source":["#load parsers\n","# parsers={}        \n","# for lang in dfg_function:\n","#     print(\"lang\",lang)\n","#     LANGUAGE = Language('build_parser/my-languages.so', lang)\n","#     parser = Parser()\n","#     parser.set_language(LANGUAGE) \n","#     parser = [parser,dfg_function[lang]]    \n","#     parsers[lang]= parser\n","    \n","print(\"Parsers :\",parsers)\n","code_tokens, dfg=extract_dataflow(example.source, parsers['java'], 'java')\n","code_tokens=[tokenizer.tokenize('@ '+x)[1:] if idx!=0 else tokenizer.tokenize(x) for idx,x in enumerate(code_tokens)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OKPS7Qe4FHak"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7kMTZDZxFHal"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qCgXc3ZCVjUD"},"outputs":[],"source":["device = torch.device('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1007,"status":"ok","timestamp":1681509260241,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"BA0_O1fkUgGN","outputId":"f106ef29-5071-4ab9-aebf-8040a546ab80"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 271.56it/s]\n","  0%|          | 0/1 [00:00<?, ?it/s]<ipython-input-15-5cd716aefcf6>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  attn_mask=np.zeros((self.max_source_length,self.max_source_length),dtype=np.bool)\n","100%|██████████| 1/1 [00:00<00:00,  1.10it/s]"]},{"name":"stdout","output_type":"stream","text":["[2716, 1076, 5457, 646, 27779, 25606, 114, 36, 1076, 479, 5933, 8061, 204, 4839, 25522, 3780, 479, 3116, 36, 22, 22, 4839, 25606, 35524, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","let al = [ ] ; if ( al . length > 4 ) { document . write ( \" \" ) ; }\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# eval_examples = read_examples(file)\n","eval_features = convert_examples_to_features(examples, tokenizer,stage='test')\n","eval_data = TextDataset(eval_features, max_source_length) \n","\n","# Calculate bleu\n","eval_sampler = SequentialSampler(eval_data)\n","eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size,num_workers=4)\n","\n","model.eval() \n","p=[]\n","for batch in tqdm(eval_dataloader,total=len(eval_dataloader)):\n","    batch = tuple(t.to(device) for t in batch)\n","    source_ids,source_mask,position_idx,att_mask,target_ids,target_mask = batch                    \n","    with torch.no_grad():\n","        preds = model(source_ids,source_mask,position_idx,att_mask) \n","        for pred in preds:\n","            t=pred[0].cpu().numpy()\n","            t=list(t)\n","            print(t)\n","            if 0 in t:\n","                t=t[:t.index(0)]\n","            text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n","            print(text)\n","            p.append(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1681509260242,"user":{"displayName":"Dilan_JT","userId":"02931267418306191608"},"user_tz":-330},"id":"-_8yku71bb77","outputId":"7a878a80-f907-4f6f-e611-f525a4060782"},"outputs":[{"data":{"text/plain":["['let al = [ ] ; if ( al . length > 4 ) { document . write ( \" \" ) ; }']"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["p"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_7c9JcHbFHal"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mG63TlY_FHal"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCOj8GmHFHal"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"7185d61c927ddfb37d1dd8c83ef96f8f112620be1468d632fb729d0423a9e939"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"4bc870c0bbb14ea8acb74ba2e83f7671":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17d14c7456ab4f55b6c19d6a54745711","IPY_MODEL_069890ec49124f338a0763743d9364fa","IPY_MODEL_13894002b6564362b50a985d24c2133b"],"layout":"IPY_MODEL_da6234b794854404ae3405cd3db43abb"}},"17d14c7456ab4f55b6c19d6a54745711":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b91537d2e95645799e92ca3664767a08","placeholder":"​","style":"IPY_MODEL_2891390f37894ff6a70797fee4d3bbc7","value":"Downloading (…)lve/main/config.json: 100%"}},"069890ec49124f338a0763743d9364fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_481fab40fc1b4d128a8caef6489c7a00","max":539,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32b1af328284431d952c1fdf472604d6","value":539}},"13894002b6564362b50a985d24c2133b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a776ed44fff42c3aaa4511b118c2aca","placeholder":"​","style":"IPY_MODEL_21e8827b8eaa4a72a0cef1ea72736231","value":" 539/539 [00:00&lt;00:00, 36.7kB/s]"}},"da6234b794854404ae3405cd3db43abb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b91537d2e95645799e92ca3664767a08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2891390f37894ff6a70797fee4d3bbc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"481fab40fc1b4d128a8caef6489c7a00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32b1af328284431d952c1fdf472604d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a776ed44fff42c3aaa4511b118c2aca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21e8827b8eaa4a72a0cef1ea72736231":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76c85f657655410788a1be2ac75132d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_499702c3cb7e466db645d151f7e73b7c","IPY_MODEL_60ad2dae21e74057a54fd2b34ec7fe4f","IPY_MODEL_25a54a192ffc410299c66acad4304b96"],"layout":"IPY_MODEL_c6317caf45e7412e9eaa43fe1b7de75f"}},"499702c3cb7e466db645d151f7e73b7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_201c1b47eef14ca29862c0542905ef56","placeholder":"​","style":"IPY_MODEL_957331b112894fd4b446accdf5f9c583","value":"Downloading (…)olve/main/vocab.json: 100%"}},"60ad2dae21e74057a54fd2b34ec7fe4f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4752d3f4a294af7847850a06afb937e","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05d49f42b6254d17bafc4341c981e619","value":898822}},"25a54a192ffc410299c66acad4304b96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f24e98e8c82429f950fd89f7b3d2dd4","placeholder":"​","style":"IPY_MODEL_e1d20d159700486595df24f9ff53d626","value":" 899k/899k [00:00&lt;00:00, 2.77MB/s]"}},"c6317caf45e7412e9eaa43fe1b7de75f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"201c1b47eef14ca29862c0542905ef56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"957331b112894fd4b446accdf5f9c583":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4752d3f4a294af7847850a06afb937e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05d49f42b6254d17bafc4341c981e619":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f24e98e8c82429f950fd89f7b3d2dd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1d20d159700486595df24f9ff53d626":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4b22debe56c4cc2aca69df0444e8fca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b1e7eaa81c74942b53a8c7d2c0204cc","IPY_MODEL_5b17e632829941f5b08d28de0f703d36","IPY_MODEL_c8bc889d42ae49869f98753f459284dc"],"layout":"IPY_MODEL_839f476ebab448e3b15219498d0f33fa"}},"3b1e7eaa81c74942b53a8c7d2c0204cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a7cf6d192444ed0a2e8955a07887d73","placeholder":"​","style":"IPY_MODEL_d6f84f35701a423abae3e3c969038b8f","value":"Downloading (…)olve/main/merges.txt: 100%"}},"5b17e632829941f5b08d28de0f703d36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_655f0cf6ff6b41ce9c818567433f260b","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7905b1add1344a096598a01eccf49df","value":456318}},"c8bc889d42ae49869f98753f459284dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e385fc61f2b4065810276f5b383b0ab","placeholder":"​","style":"IPY_MODEL_bd981e62245441b7b5c9edd60e8c6129","value":" 456k/456k [00:00&lt;00:00, 26.9MB/s]"}},"839f476ebab448e3b15219498d0f33fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a7cf6d192444ed0a2e8955a07887d73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6f84f35701a423abae3e3c969038b8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"655f0cf6ff6b41ce9c818567433f260b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7905b1add1344a096598a01eccf49df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e385fc61f2b4065810276f5b383b0ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd981e62245441b7b5c9edd60e8c6129":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b9ee8508b7a4c3a914251c51143b585":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe2aa746b7d1432d81e5810f3bdf7881","IPY_MODEL_d123bfd2d4de4be5a151485ff5deaaea","IPY_MODEL_924304d88c644dde8c7bed06237d953c"],"layout":"IPY_MODEL_9b3dfa982a714584b64a3c1c1c315317"}},"fe2aa746b7d1432d81e5810f3bdf7881":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0c887af49d94d48ba50668a6dc7b373","placeholder":"​","style":"IPY_MODEL_89b01fdd6dda414ba51bb4b62ebf31fa","value":"Downloading (…)cial_tokens_map.json: 100%"}},"d123bfd2d4de4be5a151485ff5deaaea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e88a15b7f9534c219bfe3c4bd1790d38","max":772,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21456c6e6da94a258759c75d8bea8888","value":772}},"924304d88c644dde8c7bed06237d953c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1260d6a650140949ae165e7d089620b","placeholder":"​","style":"IPY_MODEL_945ebbb23048435899bd2a2335e1a50f","value":" 772/772 [00:00&lt;00:00, 57.8kB/s]"}},"9b3dfa982a714584b64a3c1c1c315317":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c887af49d94d48ba50668a6dc7b373":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89b01fdd6dda414ba51bb4b62ebf31fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e88a15b7f9534c219bfe3c4bd1790d38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21456c6e6da94a258759c75d8bea8888":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1260d6a650140949ae165e7d089620b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"945ebbb23048435899bd2a2335e1a50f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce92f0980ff443e9bada0b86be2ff049":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6064152bf5e847b498c1e0fe272b01aa","IPY_MODEL_1fbfc6dc7387458ea876c2bbcc306036","IPY_MODEL_e442d920b54346159e55704fb1e8c172"],"layout":"IPY_MODEL_a28152783b794894b7f77bbb31a34cdb"}},"6064152bf5e847b498c1e0fe272b01aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a76a77b8e4d44e2b38618fb347adafc","placeholder":"​","style":"IPY_MODEL_6757578e888443ad8d63159c0f288be6","value":"Downloading (…)okenizer_config.json: 100%"}},"1fbfc6dc7387458ea876c2bbcc306036":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_511e37c3542e4db59430cb28ba656ca7","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d01f7cc1c1b434e98760389bf1cbb84","value":25}},"e442d920b54346159e55704fb1e8c172":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59ec2689567242fd9ec693932bd6bdc3","placeholder":"​","style":"IPY_MODEL_a51d7707903e4b2daac79e582b41fbf3","value":" 25.0/25.0 [00:00&lt;00:00, 635B/s]"}},"a28152783b794894b7f77bbb31a34cdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a76a77b8e4d44e2b38618fb347adafc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6757578e888443ad8d63159c0f288be6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"511e37c3542e4db59430cb28ba656ca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d01f7cc1c1b434e98760389bf1cbb84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"59ec2689567242fd9ec693932bd6bdc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a51d7707903e4b2daac79e582b41fbf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77e7253393d5438da4e73945237bfdb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d42f12b146b467c9c962419fe710fc7","IPY_MODEL_44e4c1f859f24ae6b7fc850eb0ff39dc","IPY_MODEL_07c0356c4f324fcf9ed01bc0ab476cb7"],"layout":"IPY_MODEL_0876e399f9144ed5b55f91092e4fdea1"}},"1d42f12b146b467c9c962419fe710fc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca28db165bd64db7aaedb22456dfa0c1","placeholder":"​","style":"IPY_MODEL_4f5c4aadaa474c22bd6f7240a5e78800","value":"Downloading pytorch_model.bin: 100%"}},"44e4c1f859f24ae6b7fc850eb0ff39dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6041f5aa66f647d595017343ec79aea7","max":498845934,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6f8c8ffa39d4a609f0d506d6786b8e7","value":498845934}},"07c0356c4f324fcf9ed01bc0ab476cb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0fba310081040a8bf01d7828a40a03f","placeholder":"​","style":"IPY_MODEL_b8fe38c75e9c4ffc8dd2c035cb857333","value":" 499M/499M [00:01&lt;00:00, 286MB/s]"}},"0876e399f9144ed5b55f91092e4fdea1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca28db165bd64db7aaedb22456dfa0c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f5c4aadaa474c22bd6f7240a5e78800":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6041f5aa66f647d595017343ec79aea7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6f8c8ffa39d4a609f0d506d6786b8e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0fba310081040a8bf01d7828a40a03f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8fe38c75e9c4ffc8dd2c035cb857333":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}